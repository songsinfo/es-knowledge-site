export interface WordRoot {
  id: number;
  root: string;
  origin: string;
  meaning: string;
  description: string;
  examples: { word: string; meaning: string; explanation: string }[];
  quiz: { question: string; options: string[]; correctAnswer: number };
}

export const wordRoots: WordRoot[] = [
  { id: 1, root: "索引 (Index)", origin: "核心概念", meaning: "类似关系型数据库中的「数据库」，存储一类文档的容器", description: "在 Elasticsearch 中，Index（索引）是存储相关文档的逻辑命名空间，类似于关系型数据库中的「数据库」概念。每个索引都有自己的 Mapping（映射）来定义字段类型，以及 Settings（设置）来配置分片数、副本数等参数。索引名称必须小写，不能包含特殊字符。一个 ES 集群可以包含多个索引，每个索引可以存储数十亿条文档。索引一旦创建，主分片数量不能修改（副本分片可以动态调整），因此规划分片数量是生产环境中非常重要的工作。", examples: [{ word: "商品索引", meaning: "存储所有商品信息", explanation: "电商平台将所有商品数据存储在 `products` 索引中，包含名称、价格、分类等字段" }, { word: "日志索引", meaning: "按天分割的日志索引", explanation: "日志系统通常按天创建索引，如 `logs-2026.02.27`，便于管理和删除历史数据" }, { word: "用户索引", meaning: "存储用户账号数据", explanation: "用户服务将注册用户信息存储在 `users` 索引中，支持按用户名、邮箱快速检索" }], quiz: { question: "以下关于 ES Index 的说法，哪个是正确的？", options: ["索引创建后可以随时修改主分片数量", "索引名称可以包含大写字母", "一个索引类似于关系型数据库中的一个数据库", "一个集群只能有一个索引"], correctAnswer: 2 } },
  { id: 2, root: "文档 (Document)", origin: "核心概念", meaning: "ES 中存储数据的基本单元，以 JSON 格式表示", description: "Document（文档）是 Elasticsearch 中数据存储的最小单元，以 JSON 格式存储。每个文档都属于某个索引，并拥有唯一标识符 _id。文档可以包含嵌套对象和数组，结构非常灵活。与关系型数据库的「行」类似，但文档是无模式（schema-free）的，不同文档可以有不同的字段结构。每个文档在存储时都会被分配元数据字段，如 `_index`（所属索引）、`_id`（唯一ID）、`_source`（原始JSON数据）、`_version`（版本号）等。文档在写入时会经过分析处理，然后存入对应的分片中。", examples: [{ word: "商品文档", meaning: "一条商品数据记录", explanation: '{"id": 1001, "name": "机械键盘", "price": 299, "category": "数码"}' }, { word: "嵌套文档", meaning: "包含嵌套对象的文档", explanation: '文档可以包含嵌套对象：{"user": "张三", "address": {"city": "北京", "zip": "100000"}}' }, { word: "父子文档", meaning: "具有父子关系的文档", explanation: "通过 join 字段实现父子文档关系，适用于一对多的数据结构，如博客文章与评论" }], quiz: { question: "ES 中文档的唯一标识符字段名是？", options: ["_doc", "_id", "_uid", "_key"], correctAnswer: 1 } },
  { id: 3, root: "分片 (Shard)", origin: "分布式架构", meaning: "索引数据的水平切分单元，实现数据分布和并行处理", description: "Shard（分片）是 Elasticsearch 实现分布式存储的核心机制。一个索引可以被切分成多个分片，每个分片是一个独立的 Lucene 实例，包含索引数据的子集。分片分为两种：Primary Shard（主分片）负责处理写入和读取请求；Replica Shard（副本分片）是主分片的完整拷贝，提供高可用和读负载均衡。主分片数量在索引创建时确定，之后不能更改。建议单个分片大小控制在 20-40GB。", examples: [{ word: "主分片", meaning: "Primary Shard，负责写入", explanation: "创建索引时指定 number_of_shards=5，数据会均匀分布到5个主分片中" }, { word: "副本分片", meaning: "Replica Shard，提供高可用", explanation: "设置 number_of_replicas=1，每个主分片有1个副本，集群可容忍单节点故障" }, { word: "分片路由", meaning: "决定文档存储在哪个分片", explanation: "默认路由公式：shard = hash(document_id) % number_of_shards，可自定义路由键" }], quiz: { question: "以下关于主分片（Primary Shard）的说法，正确的是？", options: ["主分片数量可以在运行时随时修改", "主分片不参与读取请求，只负责写入", "主分片数量在索引创建后不能更改", "每个索引只能有一个主分片"], correctAnswer: 2 } },
  { id: 4, root: "倒排索引 (Inverted Index)", origin: "底层原理", meaning: "全文搜索的核心数据结构，记录词项到文档的映射关系", description: "倒排索引（Inverted Index）是 Elasticsearch 实现高效全文搜索的底层数据结构，由 Lucene 实现。与正向索引（文档→词语）相反，倒排索引记录的是词项（Term）到文档列表的映射。结构包含两部分：词典（Term Dictionary）按序存储所有词项；倒排列表（Posting List）记录包含该词项的文档ID、词频、位置等信息。查询时，ES 在词典中找到匹配的词项，再从倒排列表获取相关文档。倒排索引高效性来自于：词典使用 FST 压缩存储，BKD 树用于数值和地理位置查询。", examples: [{ word: "词项词典", meaning: "存储所有分词结果", explanation: "文本 'Elasticsearch 很强大' 分词后得到 ['elasticsearch', '很', '强大']，均存入词典" }, { word: "倒排列表", meaning: "词项对应的文档列表", explanation: "'elasticsearch' → [doc1, doc5, doc9]，表示这三个文档包含该词项" }, { word: "BM25 打分", meaning: "基于倒排索引的相关性打分", explanation: "ES 默认使用 BM25 算法，根据词频（TF）和文档频率（IDF）计算文档与查询的相关性分数" }], quiz: { question: "倒排索引中「倒排列表」存储的是什么？", options: ["文档到词项的映射", "词项到文档ID列表的映射", "文档的原始内容", "词项的词频统计"], correctAnswer: 1 } },
  { id: 5, root: "映射 (Mapping)", origin: "数据模型", meaning: "定义索引中字段的类型和处理方式，类似数据库的 Schema", description: "Mapping（映射）是 Elasticsearch 中定义索引字段结构的方式，类似关系型数据库的 Schema。Mapping 定义了每个字段的数据类型（text、keyword、integer、date、boolean 等）、分析器设置、是否建立索引等属性。ES 支持动态映射（Dynamic Mapping），会自动根据写入的数据推断字段类型，但生产环境强烈建议使用显式映射。关键字段类型区别：text 类型会经过分词处理，适合全文搜索；keyword 类型不分词，适合精确匹配、排序和聚合。", examples: [{ word: "text vs keyword", meaning: "两种字符串类型的选择", explanation: "商品名称用 text（支持模糊搜索），商品ID用 keyword（精确匹配），同一字段可用 multi-fields 同时建立两种类型" }, { word: "动态映射", meaning: "自动推断字段类型", explanation: "写入 {'age': 25} 时，ES 自动将 age 映射为 long 类型；写入 {'email': 'a@b.com'} 时映射为 text+keyword" }, { word: "日期格式", meaning: "date 类型的格式定义", explanation: '映射 date 字段时可指定格式：{"type": "date", "format": "yyyy-MM-dd HH:mm:ss||yyyy-MM-dd"}' }], quiz: { question: "以下哪种字段类型适合做聚合（Aggregation）统计？", options: ["text", "keyword", "analyzed", "fulltext"], correctAnswer: 1 } },
  { id: 6, root: "查询 DSL (Query DSL)", origin: "查询语言", meaning: "基于 JSON 的领域特定查询语言，用于构建复杂搜索条件", description: "Query DSL 是 Elasticsearch 提供的基于 JSON 的查询语言，用于构建各种搜索条件。Query DSL 分为两大类：Query Context（查询上下文）参与相关性评分，影响 _score 字段；Filter Context（过滤上下文）只做是否匹配的判断，不计算评分，可以被缓存，性能更好。常用查询类型：match（全文搜索）、term（精确匹配）、range（范围查询）、bool（布尔组合）、match_phrase（短语匹配）等。", examples: [{ word: "match 查询", meaning: "全文搜索，会分词处理", explanation: '{"query": {"match": {"title": "elasticsearch 搜索"}}} 会将关键词分词后搜索' }, { word: "term 查询", meaning: "精确匹配，不分词", explanation: '{"query": {"term": {"status": "active"}}} 精确匹配 status 字段，适合 keyword 类型字段' }, { word: "range 查询", meaning: "范围过滤条件", explanation: '{"query": {"range": {"price": {"gte": 100, "lte": 500}}}} 查询价格在100-500之间的商品' }], quiz: { question: "以下哪种查询在 Filter Context 中执行，可以被缓存？", options: ["match 查询", "multi_match 查询", "term 查询（在 filter 子句中）", "fuzzy 查询"], correctAnswer: 2 } },
  { id: 7, root: "布尔查询 (Bool Query)", origin: "查询语言", meaning: "组合多个查询条件的复合查询，支持 must/should/must_not/filter", description: "Bool Query 是 Elasticsearch 中最常用的复合查询类型，允许将多个查询条件组合在一起。包含四个子句：must（必须匹配，参与评分）、should（应该匹配，参与评分）、must_not（必须不匹配，在 Filter Context 中执行）、filter（必须匹配，不参与评分，可被缓存）。Bool 查询可以嵌套，构建任意复杂的查询逻辑。实践中，确定性过滤条件放 filter，影响排序的条件放 must/should。", examples: [{ word: "电商搜索", meaning: "结合多种条件的商品搜索", explanation: "must: 关键词匹配标题；filter: 价格范围、分类、库存>0；should: 提高热销商品权重" }, { word: "minimum_should_match", meaning: "设置 should 最少匹配数", explanation: '设置 "minimum_should_match": 1 要求至少匹配一个 should 条件' }, { word: "嵌套布尔查询", meaning: "Bool 查询嵌套使用", explanation: "外层 must 包含内层 bool（should: [A, B]），实现 (A OR B) AND C 的复杂逻辑" }], quiz: { question: "Bool 查询中，哪个子句的条件会参与相关性评分且必须匹配？", options: ["filter", "must_not", "should", "must"], correctAnswer: 3 } },
  { id: 8, root: "聚合 (Aggregation)", origin: "数据分析", meaning: "对搜索结果进行统计分析，类似 SQL 的 GROUP BY + 统计函数", description: "Aggregation 是 Elasticsearch 强大的数据分析功能，可以对搜索结果进行各种统计计算，类似于 SQL 中的 GROUP BY 和聚合函数。聚合分为三类：Metric Aggregations（指标聚合）计算数值统计，如 avg、sum、max/min、cardinality；Bucket Aggregations（桶聚合）将文档分组，如 terms、date_histogram、range；Pipeline Aggregations（管道聚合）对其他聚合结果进行二次计算。聚合可以嵌套，实现复杂的多维数据分析。", examples: [{ word: "terms 聚合", meaning: "按字段值分组统计", explanation: "统计各品类的商品数量：terms agg on category 字段，类似 SQL: SELECT category, COUNT(*) GROUP BY category" }, { word: "date_histogram", meaning: "按时间段统计", explanation: "按月统计订单量：date_histogram on order_date，calendar_interval: month，生成时间轴柱状图数据" }, { word: "嵌套聚合", meaning: "桶内再做指标计算", explanation: "先按品类分桶，再在每个桶内计算平均价格：terms + avg 嵌套，得到每个品类的平均售价" }], quiz: { question: "以下哪种聚合类型用于计算字段的平均值？", options: ["terms", "date_histogram", "avg", "bucket_sort"], correctAnswer: 2 } },
  { id: 9, root: "分析器 (Analyzer)", origin: "文本处理", meaning: "对文本进行预处理、分词、过滤的处理管道，影响全文搜索质量", description: "Analyzer 是 Elasticsearch 处理文本数据的核心组件，由三部分组成：Character Filters（字符过滤器）对原始文本预处理；Tokenizer（分词器）将文本切分成词项；Token Filters（词项过滤器）对分词结果进一步处理，如转小写、去停用词、词干提取。ES 内置多种分析器：standard（默认）、simple、whitespace。中文分词需要额外插件，最常用的是 IK Analyzer（ik_max_word/ik_smart）。", examples: [{ word: "IK 分词器", meaning: "最流行的中文分词插件", explanation: "ik_max_word: '中华人民共和国' → ['中华', '人民', '共和国', '中华人民共和国']（最细粒度）" }, { word: "自定义分析器", meaning: "组合现有组件定制分析器", explanation: "自定义分析器：html_strip 字符过滤器 + standard 分词器 + lowercase + stop 词项过滤器" }, { word: "analyze API", meaning: "测试分析器效果", explanation: "GET /_analyze 接口可以测试任意文本经过指定分析器处理后的结果，调试分词问题必备工具" }], quiz: { question: "Analyzer 中负责将文本切分成词项的组件是？", options: ["Character Filter", "Tokenizer", "Token Filter", "Stemmer"], correctAnswer: 1 } },
  { id: 10, root: "集群 (Cluster)", origin: "分布式架构", meaning: "多个 ES 节点组成的分布式系统，共同存储和处理数据", description: "Cluster 是由一个或多个 Elasticsearch 节点组成的分布式系统，共享同一个集群名称（cluster.name）。集群提供高可用性、水平扩展能力和容错性。集群中有一个 Master 节点负责集群级别的管理操作，如创建/删除索引、分配分片等。集群健康状态分为三种：Green（所有主副分片正常）、Yellow（所有主分片正常，部分副本分片未分配）、Red（部分主分片未分配，有数据不可用）。生产环境建议至少3个节点。", examples: [{ word: "集群健康检查", meaning: "查看集群状态", explanation: "GET /_cluster/health 返回集群状态（green/yellow/red）、节点数、分片分配情况等核心指标" }, { word: "脑裂问题", meaning: "集群分裂成两个独立集群", explanation: "网络分区时，两部分节点各自选举 Master，导致数据不一致。ES 7.x 后通过 quorum 机制自动避免" }, { word: "滚动重启", meaning: "不停服升级集群", explanation: "逐个重启节点：停止分片分配 → 重启节点 → 等待分片恢复 → 继续下一个节点" }], quiz: { question: "ES 集群健康状态为 Yellow 意味着什么？", options: ["所有分片正常工作", "所有主分片正常，部分副本分片未分配", "部分主分片未分配，有数据丢失风险", "集群完全不可用"], correctAnswer: 1 } },
  { id: 11, root: "节点 (Node)", origin: "分布式架构", meaning: "集群中的单个 ES 实例，承担不同角色处理集群任务", description: "Node 是运行 Elasticsearch 的单个服务实例，每个节点都有唯一的名称和 UUID。主要节点角色：Master-eligible node 参与主节点选举，负责集群管理；Data node 存储分片数据，处理 CRUD 和搜索请求；Coordinating node 接收客户端请求，分发到对应数据节点并汇总结果；Ingest node 在数据写入前进行预处理。大规模集群建议分离不同角色节点。", examples: [{ word: "Master 节点", meaning: "负责集群元数据管理", explanation: "master 节点负责索引创建/删除、分片分配、节点加入/退出等集群级别操作" }, { word: "Data 节点", meaning: "存储和搜索数据", explanation: "大规模集群中 data 节点配置大内存、高性能磁盘（SSD），独立于 master 节点部署" }, { word: "Coordinating Only 节点", meaning: "纯协调节点，不存数据", explanation: "作为负载均衡层，接收客户端请求后分发给数据节点，减轻数据节点的协调开销" }], quiz: { question: "哪种节点类型负责接收客户端请求并分发给其他节点？", options: ["Master Node", "Data Node", "Coordinating Node", "Ingest Node"], correctAnswer: 2 } },
  { id: 12, root: "Refresh", origin: "写入机制", meaning: "将内存中的数据写入文件系统缓存，使其对搜索可见", description: "Refresh 是 Elasticsearch 将内存缓冲区（In-memory buffer）中的数据写入 Lucene segment 并使其对搜索可见的过程。默认 refresh_interval 为 1 秒，这就是为什么 ES 被称为「近实时」（NRT）搜索——写入的数据最多在1秒后才能被搜索到。Refresh 操作代价较高，批量导入数据时，建议将 refresh_interval 设置为 -1 禁用自动刷新。Refresh 只是将数据写入文件系统缓存，不保证数据持久化——Flush 才保证持久化。", examples: [{ word: "近实时搜索", meaning: "1秒内数据对搜索可见", explanation: "写入文档后，默认最多1秒（refresh 后）才能搜索到，通过 ?refresh=true 可以立即刷新（有性能代价）" }, { word: "批量写入优化", meaning: "禁用自动 refresh 提升性能", explanation: "设置 refresh_interval: -1 禁用自动刷新，批量导入完成后执行 POST /logs/_refresh" }, { word: "手动 refresh", meaning: "强制立即刷新", explanation: "POST /index/_refresh 手动触发，或在写入请求中加 ?refresh=wait_for 等待下次自动刷新完成后返回" }], quiz: { question: "ES 默认的 refresh_interval 是多少？", options: ["100ms", "500ms", "1s", "5s"], correctAnswer: 2 } },
  { id: 13, root: "Flush", origin: "写入机制", meaning: "将文件系统缓存中的数据刷入磁盘，并清理事务日志", description: "Flush 是 Elasticsearch 将文件系统缓存（OS Cache）中的数据持久化到磁盘，并清除事务日志（Translog）的过程。Flush 操作由两个触发条件：Translog 大小超过阈值（默认 512MB）或超时时间（默认 30 分钟）。Flush 之前，写入的数据通过 Translog 保证持久性——节点崩溃后，ES 会通过重放 Translog 来恢复数据。理解 Refresh 和 Flush 的区别至关重要：Refresh 让数据可搜索（写入 OS Cache），Flush 让数据持久化（写入磁盘）。", examples: [{ word: "Translog 事务日志", meaning: "崩溃恢复的保障", explanation: "每次写入操作先追加到 Translog，节点崩溃重启后通过重放 Translog 恢复未 Flush 的数据" }, { word: "Flush 触发条件", meaning: "自动触发时机", explanation: "Translog 超过 512MB 或超过 30 分钟时自动 Flush；也可手动执行 POST /index/_flush" }, { word: "Refresh vs Flush", meaning: "两者的本质区别", explanation: "Refresh: Buffer → OS Cache（可搜索，不持久）；Flush: OS Cache → 磁盘（持久化，清理 Translog）" }], quiz: { question: "ES Flush 操作的主要作用是？", options: ["使写入数据对搜索可见", "将数据从 OS Cache 持久化到磁盘", "清理旧的 segment 文件", "更新倒排索引"], correctAnswer: 1 } },
  { id: 14, root: "段合并 (Segment Merge)", origin: "存储优化", meaning: "将多个小 Lucene segment 合并为大 segment，优化搜索性能", description: "Lucene 将索引数据存储在不可变的 segment 文件中。每次 Refresh 都会产生一个新的 segment，随着时间推移 segment 数量越来越多，影响搜索性能（每次搜索需要遍历所有 segment）。Segment Merge 在后台自动将多个小 segment 合并成大 segment 的过程。合并时会物理删除标记为删除的文档。Force Merge 可手动将 segment 合并到指定数量，常用于只读索引优化。", examples: [{ word: "自动合并策略", meaning: "后台自动触发合并", explanation: "ES 后台持续监控 segment 数量和大小，按 TieredMergePolicy 自动合并，无需手动干预" }, { word: "Force Merge", meaning: "手动强制合并", explanation: "POST /logs-2026.01/_forcemerge?max_num_segments=1 将历史索引合并为单个 segment，最大化搜索性能" }, { word: "删除文档真正释放", meaning: "合并时才物理删除", explanation: "DELETE 操作只在 segment 中标记文档为已删除，合并时才真正移除，磁盘空间在合并后才被释放" }], quiz: { question: "ES 中删除文档时，文档数据什么时候被真正从磁盘移除？", options: ["立即删除", "下次 Refresh 时", "下次 Flush 时", "Segment Merge 时"], correctAnswer: 3 } },
  { id: 15, root: "索引别名 (Index Alias)", origin: "运维管理", meaning: "为索引创建虚拟名称，实现零停机切换和跨索引查询", description: "Index Alias 是指向一个或多个索引的虚拟名称。别名的核心价值在于解耦应用程序与底层索引名称，实现灵活的运维操作。主要应用场景：零停机重建索引（新索引构建完成后原子切换别名）、滚动索引管理、跨索引查询、过滤别名（实现数据权限控制）。别名操作是原子的，可以同时移除旧别名和添加新别名，避免查询到不完整数据的窗口期。", examples: [{ word: "Reindex 别名切换", meaning: "零停机重建索引", explanation: "旧索引 products_v1 → 别名 products；构建完成 products_v2 后，原子操作：移除 v1 别名 + 添加 v2 别名" }, { word: "滚动索引", meaning: "按时间或大小自动创建新索引", explanation: "POST /logs/_rollover {\"conditions\": {\"max_age\": \"7d\"}}，日志超过7天自动创建新索引，别名自动指向新索引" }, { word: "过滤别名", meaning: "带条件的索引别名", explanation: "为不同租户创建过滤别名：tenant_a 别名附带 filter: {term: {tenant_id: 'a'}}，实现多租户数据隔离" }], quiz: { question: "Index Alias 最常用于哪种场景？", options: ["提升写入性能", "零停机重建索引时的无缝切换", "减少磁盘空间占用", "自动备份数据"], correctAnswer: 1 } },
  { id: 16, root: "相关性评分 (_score)", origin: "搜索排序", meaning: "衡量文档与查询匹配程度的分数，决定搜索结果排序", description: "相关性评分由 _score 字段表示，决定搜索结果的排列顺序。ES 7.x 默认使用 BM25 算法计算相关性。BM25 分数受以下因素影响：词频（TF）、逆文档频率（IDF）、字段长度（字段越短，同样词频的文档得分越高）。可以通过 Function Score Query 自定义评分逻辑，如根据销量、时间衰减、地理距离等业务因素调整分数。", examples: [{ word: "BM25 算法", meaning: "ES 默认相关性算法", explanation: "BM25 相比 TF-IDF 的改进：词频饱和（词出现100次和出现5次差别不大），并考虑文档字段长度归一化" }, { word: "Function Score", meaning: "自定义评分函数", explanation: "电商搜索中结合点击率、好评数提升热销商品排名：function_score + field_value_factor" }, { word: "explain 调试", meaning: "查看评分计算详情", explanation: "GET /index/_explain/doc_id 返回该文档对此查询的详细评分计算过程" }], quiz: { question: "ES 7.x 默认使用哪种相关性评分算法？", options: ["TF-IDF", "BM25", "PageRank", "Cosine Similarity"], correctAnswer: 1 } },
  { id: 17, root: "快照 (Snapshot)", origin: "运维管理", meaning: "对索引数据的时间点备份，支持增量备份和跨集群恢复", description: "Snapshot 是 Elasticsearch 的数据备份机制，将索引数据保存到外部存储（如 S3、HDFS、NFS 等）。快照是增量的——第一次创建完整备份，后续快照只记录变化的数据。生产环境建议使用 SLM（Snapshot Lifecycle Management）策略定期自动创建快照。快照不影响集群的正常读写操作。", examples: [{ word: "S3 仓库", meaning: "使用 S3 存储快照", explanation: "注册 S3 仓库：PUT /_snapshot/my_backup {\"type\": \"s3\", \"settings\": {\"bucket\": \"my-es-backup\"}}" }, { word: "增量备份", meaning: "只备份变化的数据", explanation: "首次快照备份全量数据；后续快照通过比对 segment 文件 UUID 只备份新增/变化的 segment，节省90%以上存储" }, { word: "SLM 策略", meaning: "快照生命周期管理", explanation: "配置 SLM Policy：每天凌晨2点自动创建快照，保留30天内的快照，超期自动删除，生产环境必备" }], quiz: { question: "ES 快照（Snapshot）支持哪种备份方式？", options: ["只支持全量备份", "增量备份", "只支持在线备份", "只支持本地磁盘存储"], correctAnswer: 1 } },
  { id: 18, root: "管道处理 (Ingest Pipeline)", origin: "数据处理", meaning: "数据写入前的预处理管道，支持字段转换、数据清洗、格式化", description: "Ingest Pipeline 是 Elasticsearch 提供的数据预处理机制，在文档写入索引之前对其进行转换和丰富处理。Pipeline 由一系列 Processor 组成，按顺序执行。常用处理器：set（设置字段值）、rename（重命名字段）、remove（删除字段）、grok（正则解析）、date（日期格式解析）、convert（类型转换）、geoip（IP 地址转地理位置）、script（自定义脚本）等。", examples: [{ word: "日志解析管道", meaning: "解析结构化日志", explanation: "使用 grok processor 解析 Nginx 访问日志，提取 IP、时间、状态码、响应时间等字段" }, { word: "GeoIP 处理器", meaning: "IP 转地理位置", explanation: "geoip processor 自动将客户端 IP 转换为城市、国家、经纬度信息，支持可视化地图分析" }, { word: "管道测试", meaning: "验证管道处理效果", explanation: "POST /_ingest/pipeline/my_pipeline/_simulate {\"docs\": [{\"_source\": {...}}]} 测试管道对样本数据的处理结果" }], quiz: { question: "Ingest Pipeline 在什么时候执行？", options: ["查询时", "索引 Refresh 时", "文档写入索引之前", "Segment Merge 时"], correctAnswer: 2 } },
  { id: 19, root: "滚动查询 (Scroll API)", origin: "查询技术", meaning: "高效遍历大量数据的查询方式，适用于全量数据导出场景", description: "Scroll API 是 Elasticsearch 提供的用于高效遍历大量数据的机制，类似于数据库的游标。普通搜索使用 from+size 翻页，当 from 很大时，ES 需要在每个分片查询 (from+size) 条数据后再归并排序，性能极差（deep pagination 问题）。Scroll API 通过在服务器端维持一个搜索上下文来解决这个问题，时间复杂度为 O(n)。适合场景：全量数据导出、数据迁移、批量处理。不适合实时用户翻页（推荐 Search After）。", examples: [{ word: "初始 Scroll 查询", meaning: "创建搜索快照并获取首批数据", explanation: "POST /index/_search?scroll=5m {\"size\": 1000, \"query\": {...}} 返回首批1000条数据和 scroll_id" }, { word: "迭代获取数据", meaning: "使用 scroll_id 获取下一批", explanation: "POST /_search/scroll {\"scroll\": \"5m\", \"scroll_id\": \"xxx\"} 获取下一批，直到返回空 hits 表示遍历完成" }, { word: "Search After 替代方案", meaning: "实时翻页的最佳实践", explanation: "实时用户翻页推荐 Search After：使用上一页最后一条记录的排序值作为下一页的起始点，无状态，支持并发" }], quiz: { question: "Scroll API 相比 from+size 翻页的主要优势是？", options: ["支持随机跳页", "适合实时用户界面翻页", "高效遍历大量数据，避免深度翻页性能问题", "查询结果更准确"], correctAnswer: 2 } },
  { id: 20, root: "冷热架构 (Hot-Warm)", origin: "架构设计", meaning: "将数据按访问频率分层存储，热数据用高性能节点，冷数据用大容量节点", description: "Hot-Warm 架构是 Elasticsearch 处理时序数据的最佳实践。根据数据访问频率将节点分层：Hot 节点使用 SSD、高 CPU 和内存，处理最新的、频繁查询的数据；Warm 节点使用大容量 HDD，存储较旧、访问较少的数据；Cold 节点存储几乎不访问的历史数据。通过 ILM（Index Lifecycle Management）策略自动管理数据在各层之间的迁移，大幅降低存储成本。", examples: [{ word: "ILM 策略", meaning: "索引生命周期管理", explanation: "配置 ILM: Hot阶段（每天rollover）→ Warm（7天后迁移，关闭replica）→ Cold（30天后）→ Delete（90天后）" }, { word: "节点属性", meaning: "标记节点所属层级", explanation: "在 elasticsearch.yml 中设置 node.attr.data: hot/warm/cold，ILM 根据此属性将分片路由到对应层级节点" }, { word: "存储成本优化", meaning: "冷热分层降低成本", explanation: "Hot节点（SSD）存最近7天数据，Warm节点（HDD）存7-30天，总成本可降低60%-80%" }], quiz: { question: "在冷热架构中，哪个组件负责自动管理数据在各层之间的迁移？", options: ["SLM", "ILM", "Segment Merge Policy", "Shard Allocation"], correctAnswer: 1 } },
  { id: 21, root: "高亮显示 (Highlight)", origin: "搜索功能", meaning: "在搜索结果中标记命中词项的位置，提升搜索体验", description: "Highlight 是 Elasticsearch 在搜索结果中标记命中词项的功能。ES 支持三种高亮模式：unified（默认，使用 BM25 打分，通常是最佳选择）、plain（基础模式）、fvh（Fast Vector Highlighter，大字段性能最好，需要字段启用 term_vector）。高亮结果以片段形式返回，可以配置片段大小、数量和分隔符。高亮通过在匹配词项周围添加 HTML 标签（默认 `<em>`）实现，可自定义开始/结束标签。", examples: [{ word: "基础高亮配置", meaning: "为搜索结果添加高亮", explanation: '在查询中添加 "highlight": {"fields": {"title": {}, "content": {"fragment_size": 150}}}' }, { word: "自定义高亮标签", meaning: "替换默认的 em 标签", explanation: '"pre_tags": ["<mark>"], "post_tags": ["</mark>"] 将高亮词用 <mark> 标签包裹' }, { word: "FVH 模式", meaning: "大字段快速高亮", explanation: "对于正文等大文本字段，在 mapping 中设置 term_vector: with_positions_offsets，使用 fvh 模式性能提升明显" }], quiz: { question: "ES 高亮显示默认使用哪种模式？", options: ["plain", "fvh", "unified", "standard"], correctAnswer: 2 } },
  { id: 22, root: "多租户 (Multi-tenancy)", origin: "架构设计", meaning: "在单一 ES 集群中隔离多个租户的数据和访问权限", description: "Multi-tenancy 是在单个 Elasticsearch 集群中为多个用户/组织提供相互隔离服务的架构模式。常见实现方案：每个租户独立索引（最强隔离，管理成本高）；共享索引 + 字段隔离（适合小租户场景）；索引别名 + 过滤（应用层无感知）。安全控制通过 X-Pack Security 实现：Document-level Security 限制用户只能看自己的文档；Field-level Security 隐藏敏感字段。", examples: [{ word: "索引级隔离", meaning: "每租户独立索引", explanation: "SaaS 产品为每个企业客户创建独立索引：company_abc_data、company_xyz_data，数据完全隔离" }, { word: "文档级安全", meaning: "Document-level Security", explanation: "X-Pack Security 配置：user A 只能看到 tenant_id=A 的文档，即使查询了整个索引也无法访问其他租户数据" }, { word: "过滤别名", meaning: "透明的租户隔离", explanation: "为租户 A 创建别名 tenant_a，附带 filter: {term: {tenant_id: 'a'}}，应用直接查询别名" }], quiz: { question: "以下哪种多租户隔离方案数据隔离性最强？", options: ["共享索引 + tenant_id 字段", "索引别名 + 过滤条件", "每个租户独立索引", "Document-level Security"], correctAnswer: 2 } },
  { id: 23, root: "性能调优 (Performance Tuning)", origin: "运维优化", meaning: "通过配置优化提升 ES 集群的写入速度、查询性能和资源利用率", description: "Elasticsearch 性能调优涉及多个维度。写入性能优化：批量写入（Bulk API，推荐每批 5-15MB）、禁用 replica（写入期间）、增大 refresh_interval、使用 SSD、优化 JVM 堆大小（不超过物理内存50%，且不超过32GB）。查询性能优化：使用 Filter Context 利用缓存、避免 wildcard 前缀通配符查询、合理设置分片数量、善用 keyword 字段聚合。", examples: [{ word: "Bulk API", meaning: "批量写入提升性能", explanation: "POST /_bulk 一次请求批量写入多条文档，减少网络开销；推荐每批5-15MB" }, { word: "JVM 堆配置", meaning: "ES 内存调优关键", explanation: "堆大小设置为物理内存的50%，且不超过32GB（保证 JVM 使用压缩指针）；另一半留给 OS Cache" }, { word: "慢查询日志", meaning: "定位性能问题", explanation: "配置 slowlog：超过5秒的查询记录到日志，分析 explain 找出性能瓶颈" }], quiz: { question: "ES JVM 堆大小为什么不建议超过 32GB？", options: ["ES 不支持超过32GB内存", "超过32GB后JVM无法使用压缩指针，实际内存效率降低", "超过32GB会导致GC停顿时间过长", "操作系统限制单进程最大内存为32GB"], correctAnswer: 1 } },
  { id: 24, root: "向量搜索 (Vector Search)", origin: "AI 搜索", meaning: "基于语义向量相似度的搜索，实现语义理解和以图搜图等能力", description: "Vector Search 是 Elasticsearch 8.x 的重要新特性，支持存储高维向量并通过近似最近邻（ANN）算法进行相似度搜索。通过将文本、图像等非结构化数据转化为向量（Embedding），可以实现语义搜索、图像相似搜索、推荐系统等 AI 应用。ES 使用 HNSW 算法实现高效 ANN 搜索。支持与传统 BM25 关键词搜索结合（Hybrid Search），大幅提升搜索质量。", examples: [{ word: "语义搜索", meaning: "基于含义而非关键词的搜索", explanation: "搜索 '价格实惠的手机' 能找到含 '平价手机'、'便宜智能机' 的文档，即使不含完全相同的词语" }, { word: "dense_vector 字段", meaning: "存储向量数据的字段类型", explanation: 'Mapping 定义：{"embedding": {"type": "dense_vector", "dims": 768, "index": true, "similarity": "cosine"}}' }, { word: "混合搜索", meaning: "关键词 + 语义向量结合", explanation: "Reciprocal Rank Fusion（RRF）融合 BM25 关键词分数和向量相似度分数，综合排序，效果优于单独使用任一方式" }], quiz: { question: "Elasticsearch 向量搜索使用哪种算法实现高效的近似最近邻搜索？", options: ["KD-Tree", "BM25", "HNSW", "LSH"], correctAnswer: 2 } },
  { id: 25, root: "集群监控 (Monitoring)", origin: "运维管理", meaning: "实时观测集群健康状态、性能指标和资源使用情况", description: "Elasticsearch 集群监控是生产运维的核心环节。关键监控指标：集群状态（green/yellow/red）、节点 JVM 堆内存使用率（建议不超过75%）、CPU 使用率、磁盘使用率（超过85%触发 watermark 限制写入）、索引速率和查询延迟、GC 频率和时长。监控工具：Kibana + Elastic Stack Monitoring（原生）、Prometheus + Grafana（通用方案）。告警策略：JVM 堆 > 85%、磁盘 > 85%、集群状态 Red 等需立即告警。", examples: [{ word: "节点 Stats API", meaning: "获取节点详细统计信息", explanation: "GET /_nodes/stats 返回各节点的 JVM、OS、索引统计、线程池、文件系统等完整监控数据" }, { word: "Prometheus 监控", meaning: "主流监控方案", explanation: "部署 elasticsearch_exporter 采集 ES 指标推送到 Prometheus，Grafana 展示仪表盘，AlertManager 发告警" }, { word: "磁盘 Watermark", meaning: "磁盘使用率阈值保护", explanation: "低水位85%停止分配新分片，高水位90%开始迁移分片，可调整 cluster.routing.allocation.disk.watermark 参数" }], quiz: { question: "ES JVM 堆内存使用率超过多少时需要立即告警？", options: ["60%", "75%", "85%", "95%"], correctAnswer: 2 } },
];
